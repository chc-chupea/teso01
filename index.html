<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>手相診断アプリ</title>
  <style>
    body {
      font-family: "Rounded Mplus 1c", "Hiragino Sans", sans-serif;
      background: #f0f4f8;
      color: #333;
      text-align: center;
      padding: 1rem;
    }
    h1 {
      font-size: 1.8rem;
      color: #4a7ebB;
    }
    select, button {
      padding: 0.7em;
      font-size: 1rem;
      margin: 1em;
      border-radius: 1em;
      border: none;
      background: #e6efff;
      color: #333;
    }
    video, canvas, img {
      max-width: 100%;
      border-radius: 1rem;
      margin-top: 1rem;
    }
    #results {
      margin-top: 1em;
      padding: 1em;
      background: #ffffff;
      border-radius: 1rem;
      box-shadow: 0 4px 6px rgba(0,0,0,0.1);
    }
    .share-buttons {
      margin-top: 1em;
    }
    .share-buttons button {
      background: #d0eaff;
    }
  </style>
</head>
<body>
  <h1>ゆるふわ手相診断</h1>
  <p>ジャンルを選んでください：</p>
  <select id="genre">
    <option value="">--ジャンルを選択--</option>
    <option value="romance">恋愛</option>
    <option value="work">仕事</option>
    <option value="money">金運</option>
    <option value="health">健康</option>
    <option value="personality">性格</option>
    <option value="all">全部自動診断</option>
  </select>
  <br>
  <button onclick="startCamera()">カメラを起動</button>
  <button onclick="switchCamera()">カメラ切替</button>
  <br>
  <video id="video" autoplay playsinline></video>
  <br>
  <button onclick="takePhoto()">📸 シャッター</button>
  <canvas id="canvas" style="display:none;"></canvas>
  <canvas id="lineCanvas" style="display:none;"></canvas>
  <div id="results"></div>
  <div class="share-buttons">
    <button onclick="shareLine()">LINEでシェア</button>
    <button onclick="shareInsta()">インスタで送る</button>
  </div>

  <script async src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
  <script async src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js"></script>
  <script async src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
  <script async src="https://docs.opencv.org/4.x/opencv.js" onload="onOpenCvReady();"></script>

  <script>
    let stream;
    let usingFront = false;
    const videoElement = document.getElementById('video');
    const canvas = document.getElementById('canvas');
    const lineCanvas = document.getElementById('lineCanvas');

    async function startCamera() {
      if (stream) {
        stream.getTracks().forEach(track => track.stop());
      }
      const constraints = {
        video: {
          facingMode: usingFront ? 'user' : 'environment'
        }
      };
      stream = await navigator.mediaDevices.getUserMedia(constraints);
      videoElement.srcObject = stream;

      const hands = new Hands({locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`});
      hands.setOptions({
        maxNumHands: 1,
        modelComplexity: 1,
        minDetectionConfidence: 0.7,
        minTrackingConfidence: 0.7
      });
      hands.onResults(onResults);

      const camera = new Camera(videoElement, {
        onFrame: async () => {
          await hands.send({image: videoElement});
        },
        width: 640,
        height: 480
      });
      camera.start();
    }

    function switchCamera() {
      usingFront = !usingFront;
      startCamera();
    }

    function takePhoto() {
      canvas.width = videoElement.videoWidth;
      canvas.height = videoElement.videoHeight;
      const ctx = canvas.getContext('2d');
      ctx.drawImage(videoElement, 0, 0);
      new Audio('camera-shutter.mp3').play();
      setTimeout(() => detectPalmLines(), 500);
    }

    function detectPalmLines() {
      lineCanvas.width = canvas.width;
      lineCanvas.height = canvas.height;
      let src = cv.imread(canvas);
      let dst = new cv.Mat();
      cv.cvtColor(src, src, cv.COLOR_RGBA2GRAY);
      cv.GaussianBlur(src, src, new cv.Size(5, 5), 0, 0);
      cv.Canny(src, dst, 50, 150, 3, false);
      cv.imshow("lineCanvas", dst);

      document.getElementById('results').innerHTML += '<p>手の線を検出しました（感情線・頭脳線・生命線）</p>';
      const dataURL = lineCanvas.toDataURL();
      document.getElementById('results').innerHTML += `<img src="${dataURL}" alt="線検出画像">`;

      src.delete();
      dst.delete();
    }

    function onResults(results) {
      if (!results.multiHandLandmarks || results.multiHandLandmarks.length === 0) return;
      const hand = results.multiHandLandmarks[0];
      let extendedFingers = 0;
      const fingerTips = [8, 12, 16, 20];

      fingerTips.forEach((tip, idx) => {
        const mcp = hand[tip - 2];
        const pip = hand[tip - 1];
        if (hand[tip].y < pip.y && pip.y < mcp.y) {
          extendedFingers++;
        }
      });

      if (hand[4].x < hand[3].x) extendedFingers++;
      document.getElementById('results').innerHTML = `<p>指の本数検出：${extendedFingers}本</p>`;
    }

    function shareLine() {
      const url = encodeURIComponent(window.location.href);
      const text = encodeURIComponent("合コンで使える！あなたの手相診断結果はこちら→");
      window.open(`https://line.me/R/msg/text/?${text}%20${url}`);
    }

    function shareInsta() {
      alert("インスタDMはこの画面のスクショを送ってみてね💬");
    }

    function onOpenCvReady() {
      console.log('OpenCV.js is ready');
    }
  </script>
</body>
</html>
